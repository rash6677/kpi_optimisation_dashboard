{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Uqk2ihvBQob"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TdYxI8sSBqIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install mysql-connector-python\n",
        "%pip install faker\n",
        "%pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AabO_yxUBhT-",
        "outputId": "68d5e42e-6987-4940-ba63-b12dd6e10452"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mysql-connector-python in /usr/local/lib/python3.12/dist-packages (9.4.0)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.12/dist-packages (37.6.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine, text\n",
        "import mysql.connector\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from scipy import stats\n",
        "import streamlit as st\n",
        "from openpyxl import Workbook\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "W_nnGrAVBrf_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGTMnDVRQ-is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Generate synthetic e-commerce data similar to Meesho\n",
        "def generate_ecommerce_data(num_orders=10000):\n",
        "    data = []\n",
        "\n",
        "    # Product categories relevant to Meesho\n",
        "    categories = ['Fashion', 'Beauty', 'Home & Kitchen', 'Electronics', 'Kids', 'Bags']\n",
        "    cities = ['Bangalore', 'Delhi', 'Mumbai', 'Chennai', 'Hyderabad', 'Kolkata', 'Pune', 'Ahmedabad']\n",
        "\n",
        "    start_date = datetime(2024, 1, 1)\n",
        "    end_date = datetime(2025, 8, 30)\n",
        "\n",
        "    for i in range(num_orders):\n",
        "        order_date = fake.date_between(start_date=start_date, end_date=end_date)\n",
        "\n",
        "        # Generate realistic business patterns\n",
        "        base_price = np.random.exponential(300) + 50  # Price distribution\n",
        "        quantity = np.random.choice([1, 2, 3, 4], p=[0.6, 0.25, 0.1, 0.05])\n",
        "         # Weekend boost\n",
        "        if order_date.weekday() >= 5:\n",
        "            base_price *= 1.1\n",
        "\n",
        "        order_data = {\n",
        "            'order_id': f'ORD{str(i+1).zfill(6)}',\n",
        "            'order_date': order_date,\n",
        "            'customer_id': f'CUST{random.randint(1, 3000)}',\n",
        "            'product_id': f'PROD{random.randint(1, 500)}',\n",
        "            'product_category': random.choice(categories),\n",
        "            'quantity': quantity,\n",
        "            'unit_price': round(base_price, 2),\n",
        "            'total_price': round(base_price * quantity, 2),\n",
        "            'customer_city': random.choice(cities),\n",
        "            'discount_percent': random.choice([0, 5, 10, 15, 20]),\n",
        "            'payment_method': random.choice(['UPI', 'Credit_Card', 'Debit_Card', 'COD']),\n",
        "            'delivery_days': random.randint(2, 7)\n",
        "        }\n",
        "        # Apply discount\n",
        "        discount_amount = order_data['total_price'] * (order_data['discount_percent'] / 100)\n",
        "        order_data['final_price'] = round(order_data['total_price'] - discount_amount, 2)\n",
        "        order_data['discount_amount'] = round(discount_amount, 2)\n",
        "\n",
        "        data.append(order_data)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "    # Generate the dataset\n",
        "df = generate_ecommerce_data(10000)\n",
        "print(\"Dataset created successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5p-qQHPCMpO",
        "outputId": "a00221b0-9ec7-4ccd-8264-58494d4be6af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created successfully!\n",
            "Dataset shape: (10000, 14)\n",
            "\n",
            "First 5 rows:\n",
            "    order_id  order_date customer_id product_id product_category  quantity  \\\n",
            "0  ORD000001  2024-05-20    CUST2620     PROD58          Fashion         4   \n",
            "1  ORD000002  2025-03-13     CUST420    PROD347             Bags         1   \n",
            "2  ORD000003  2024-12-12     CUST123     PROD48           Beauty         1   \n",
            "3  ORD000004  2024-11-27     CUST815    PROD367             Bags         3   \n",
            "4  ORD000005  2025-05-27    CUST1140    PROD415          Fashion         2   \n",
            "\n",
            "   unit_price  total_price customer_city  discount_percent payment_method  \\\n",
            "0      190.78       763.12     Hyderabad                 5    Credit_Card   \n",
            "1      445.02       445.02         Delhi                20            COD   \n",
            "2      100.89       100.89       Chennai                20            UPI   \n",
            "3       67.95       203.85          Pune                 5            COD   \n",
            "4      325.72       651.45        Mumbai                15     Debit_Card   \n",
            "\n",
            "   delivery_days  final_price  discount_amount  \n",
            "0              3       724.96            38.16  \n",
            "1              2       356.02            89.00  \n",
            "2              6        80.71            20.18  \n",
            "3              6       193.66            10.19  \n",
            "4              4       553.73            97.72  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Create SQLite database\n",
        "conn = sqlite3.connect('meesho_analytics.db')\n",
        "\n",
        "# Save DataFrame to database\n",
        "df.to_sql('orders', conn, if_exists='replace', index=False)\n",
        "\n",
        "print(\"Data saved to SQLite database!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhNFawjGCT-M",
        "outputId": "ae89c28e-9084-426f-afee-95ac857891b0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to SQLite database!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to execute SQL queries\n",
        "def execute_query(query, description=\"\"):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Query: {description}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"SQL: {query}\")\n",
        "    print(f\"{'-'*50}\")\n",
        "\n",
        "    result = pd.read_sql_query(query, conn)\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "# 1. Monthly Revenue Trend with Growth Rate\n",
        "monthly_revenue_query = \"\"\"\n",
        "WITH monthly_stats AS (\n",
        "    SELECT\n",
        "        strftime('%Y-%m', order_date) as month,\n",
        "        COUNT(*) as total_orders,\n",
        "        SUM(final_price) as total_revenue,\n",
        "        AVG(final_price) as avg_order_value,\n",
        "        COUNT(DISTINCT customer_id) as unique_customers\n",
        "    FROM orders\n",
        "    GROUP BY strftime('%Y-%m', order_date)\n",
        "),\n",
        "revenue_growth AS (\n",
        "    SELECT *,\n",
        "        LAG(total_revenue) OVER (ORDER BY month) as prev_month_revenue,\n",
        "        ROUND(\n",
        "            ((total_revenue - LAG(total_revenue) OVER (ORDER BY month)) * 100.0 /\n",
        "            LAG(total_revenue) OVER (ORDER BY month)), 2\n",
        "        ) as revenue_growth_pct\n",
        "    FROM monthly_stats\n",
        ")\n",
        "SELECT * FROM revenue_growth ORDER BY month;\n",
        "\"\"\"\n",
        "\n",
        "monthly_data = execute_query(monthly_revenue_query, \"Monthly Revenue Trend with Growth Rate\")\n",
        "\n",
        "# 2. Customer Segmentation by Purchase Behavior\n",
        "customer_segmentation_query = \"\"\"\n",
        "WITH customer_metrics AS (\n",
        "    SELECT\n",
        "        customer_id,\n",
        "        COUNT(*) as order_frequency,\n",
        "        SUM(final_price) as total_spent,\n",
        "        AVG(final_price) as avg_order_value,\n",
        "        MAX(order_date) as last_order_date,\n",
        "        MIN(order_date) as first_order_date,\n",
        "        julianday('2025-08-30') - julianday(MAX(order_date)) as days_since_last_order\n",
        "    FROM orders\n",
        "    GROUP BY customer_id\n",
        ")\n",
        "SELECT\n",
        "    CASE\n",
        "        WHEN total_spent >= 5000 AND order_frequency >= 5 THEN 'High Value'\n",
        "        WHEN total_spent >= 2000 AND order_frequency >= 3 THEN 'Medium Value'\n",
        "        WHEN days_since_last_order <= 30 THEN 'Recent Active'\n",
        "        WHEN days_since_last_order > 90 THEN 'At Risk'\n",
        "        ELSE 'Regular'\n",
        "    END as customer_segment,\n",
        "    COUNT(*) as customer_count,\n",
        "    ROUND(AVG(total_spent), 2) as avg_total_spent,\n",
        "    ROUND(AVG(order_frequency), 2) as avg_order_frequency\n",
        "FROM customer_metrics\n",
        "GROUP BY customer_segment\n",
        "ORDER BY customer_count DESC;\n",
        "\"\"\"\n",
        "\n",
        "customer_segments = execute_query(customer_segmentation_query, \"Customer Segmentation Analysis\")\n",
        "\n",
        "# 3. Product Performance Analysis with Statistical Insights\n",
        "product_performance_query = \"\"\"\n",
        "SELECT\n",
        "    product_category,\n",
        "    COUNT(*) as total_orders,\n",
        "    SUM(quantity) as total_quantity_sold,\n",
        "    ROUND(SUM(final_price), 2) as total_revenue,\n",
        "    ROUND(AVG(final_price), 2) as avg_order_value,\n",
        "    ROUND(AVG(discount_percent), 2) as avg_discount_rate,\n",
        "    COUNT(DISTINCT customer_id) as unique_customers,\n",
        "    ROUND(SUM(final_price) * 100.0 / (SELECT SUM(final_price) FROM orders), 2) as revenue_share_pct\n",
        "FROM orders\n",
        "GROUP BY product_category\n",
        "ORDER BY total_revenue DESC;\n",
        "\"\"\"\n",
        "\n",
        "product_performance = execute_query(product_performance_query, \"Product Category Performance\")\n",
        "\n",
        "# 4. City-wise Business Analysis\n",
        "city_analysis_query = \"\"\"\n",
        "SELECT\n",
        "    customer_city,\n",
        "    COUNT(*) as total_orders,\n",
        "    ROUND(SUM(final_price), 2) as total_revenue,\n",
        "    ROUND(AVG(final_price), 2) as avg_order_value,\n",
        "    COUNT(DISTINCT customer_id) as unique_customers,\n",
        "    ROUND(AVG(delivery_days), 1) as avg_delivery_days,\n",
        "    ROUND(\n",
        "        SUM(final_price) / COUNT(DISTINCT customer_id), 2\n",
        "    ) as revenue_per_customer\n",
        "FROM orders\n",
        "GROUP BY customer_city\n",
        "ORDER BY total_revenue DESC;\n",
        "\"\"\"\n",
        "\n",
        "city_analysis = execute_query(city_analysis_query, \"City-wise Business Performance\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FoeIEYlD9_-",
        "outputId": "d3965a89-afbb-405e-e1aa-ba7855ef0d5b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Query: Monthly Revenue Trend with Growth Rate\n",
            "==================================================\n",
            "SQL: \n",
            "WITH monthly_stats AS (\n",
            "    SELECT \n",
            "        strftime('%Y-%m', order_date) as month,\n",
            "        COUNT(*) as total_orders,\n",
            "        SUM(final_price) as total_revenue,\n",
            "        AVG(final_price) as avg_order_value,\n",
            "        COUNT(DISTINCT customer_id) as unique_customers\n",
            "    FROM orders\n",
            "    GROUP BY strftime('%Y-%m', order_date)\n",
            "),\n",
            "revenue_growth AS (\n",
            "    SELECT *,\n",
            "        LAG(total_revenue) OVER (ORDER BY month) as prev_month_revenue,\n",
            "        ROUND(\n",
            "            ((total_revenue - LAG(total_revenue) OVER (ORDER BY month)) * 100.0 / \n",
            "            LAG(total_revenue) OVER (ORDER BY month)), 2\n",
            "        ) as revenue_growth_pct\n",
            "    FROM monthly_stats\n",
            ")\n",
            "SELECT * FROM revenue_growth ORDER BY month;\n",
            "\n",
            "--------------------------------------------------\n",
            "      month  total_orders  total_revenue  avg_order_value  unique_customers  \\\n",
            "0   2024-01           522      261365.14       500.699502               479   \n",
            "1   2024-02           479      233926.97       488.365282               452   \n",
            "2   2024-03           517      275448.32       532.782050               480   \n",
            "3   2024-04           519      251667.37       484.908227               475   \n",
            "4   2024-05           496      231887.89       467.515907               458   \n",
            "5   2024-06           488      261296.44       535.443525               447   \n",
            "6   2024-07           559      299462.34       535.710805               513   \n",
            "7   2024-08           526      260682.99       495.595038               479   \n",
            "8   2024-09           517      258549.04       500.094855               467   \n",
            "9   2024-10           485      244365.82       503.847052               438   \n",
            "10  2024-11           508      248657.52       489.483307               467   \n",
            "11  2024-12           537      274370.49       510.932011               494   \n",
            "12  2025-01           478      258557.43       540.915126               445   \n",
            "13  2025-02           446      221446.12       496.515964               418   \n",
            "14  2025-03           494      242125.26       490.132105               459   \n",
            "15  2025-04           486      256177.52       527.114239               453   \n",
            "16  2025-05           455      230476.65       506.542088               411   \n",
            "17  2025-06           524      288465.50       550.506679               489   \n",
            "18  2025-07           519      261015.45       502.919942               475   \n",
            "19  2025-08           445      240535.17       540.528472               414   \n",
            "\n",
            "    prev_month_revenue  revenue_growth_pct  \n",
            "0                  NaN                 NaN  \n",
            "1            261365.14              -10.50  \n",
            "2            233926.97               17.75  \n",
            "3            275448.32               -8.63  \n",
            "4            251667.37               -7.86  \n",
            "5            231887.89               12.68  \n",
            "6            261296.44               14.61  \n",
            "7            299462.34              -12.95  \n",
            "8            260682.99               -0.82  \n",
            "9            258549.04               -5.49  \n",
            "10           244365.82                1.76  \n",
            "11           248657.52               10.34  \n",
            "12           274370.49               -5.76  \n",
            "13           258557.43              -14.35  \n",
            "14           221446.12                9.34  \n",
            "15           242125.26                5.80  \n",
            "16           256177.52              -10.03  \n",
            "17           230476.65               25.16  \n",
            "18           288465.50               -9.52  \n",
            "19           261015.45               -7.85  \n",
            "\n",
            "==================================================\n",
            "Query: Customer Segmentation Analysis\n",
            "==================================================\n",
            "SQL: \n",
            "WITH customer_metrics AS (\n",
            "    SELECT \n",
            "        customer_id,\n",
            "        COUNT(*) as order_frequency,\n",
            "        SUM(final_price) as total_spent,\n",
            "        AVG(final_price) as avg_order_value,\n",
            "        MAX(order_date) as last_order_date,\n",
            "        MIN(order_date) as first_order_date,\n",
            "        julianday('2025-08-30') - julianday(MAX(order_date)) as days_since_last_order\n",
            "    FROM orders\n",
            "    GROUP BY customer_id\n",
            ")\n",
            "SELECT \n",
            "    CASE \n",
            "        WHEN total_spent >= 5000 AND order_frequency >= 5 THEN 'High Value'\n",
            "        WHEN total_spent >= 2000 AND order_frequency >= 3 THEN 'Medium Value'\n",
            "        WHEN days_since_last_order <= 30 THEN 'Recent Active'\n",
            "        WHEN days_since_last_order > 90 THEN 'At Risk'\n",
            "        ELSE 'Regular'\n",
            "    END as customer_segment,\n",
            "    COUNT(*) as customer_count,\n",
            "    ROUND(AVG(total_spent), 2) as avg_total_spent,\n",
            "    ROUND(AVG(order_frequency), 2) as avg_order_frequency\n",
            "FROM customer_metrics\n",
            "GROUP BY customer_segment\n",
            "ORDER BY customer_count DESC;\n",
            "\n",
            "--------------------------------------------------\n",
            "  customer_segment  customer_count  avg_total_spent  avg_order_frequency\n",
            "0          At Risk            1298          1031.94                 2.56\n",
            "1     Medium Value             844          2991.76                 4.79\n",
            "2          Regular             454          1171.75                 3.13\n",
            "3    Recent Active             229          1168.59                 3.17\n",
            "4       High Value              71          6146.50                 6.89\n",
            "\n",
            "==================================================\n",
            "Query: Product Category Performance\n",
            "==================================================\n",
            "SQL: \n",
            "SELECT \n",
            "    product_category,\n",
            "    COUNT(*) as total_orders,\n",
            "    SUM(quantity) as total_quantity_sold,\n",
            "    ROUND(SUM(final_price), 2) as total_revenue,\n",
            "    ROUND(AVG(final_price), 2) as avg_order_value,\n",
            "    ROUND(AVG(discount_percent), 2) as avg_discount_rate,\n",
            "    COUNT(DISTINCT customer_id) as unique_customers,\n",
            "    ROUND(SUM(final_price) * 100.0 / (SELECT SUM(final_price) FROM orders), 2) as revenue_share_pct\n",
            "FROM orders\n",
            "GROUP BY product_category\n",
            "ORDER BY total_revenue DESC;\n",
            "\n",
            "--------------------------------------------------\n",
            "  product_category  total_orders  total_quantity_sold  total_revenue  \\\n",
            "0      Electronics          1795                 2845      925412.87   \n",
            "1   Home & Kitchen          1651                 2677      856110.48   \n",
            "2             Kids          1685                 2685      843479.64   \n",
            "3             Bags          1665                 2637      830554.79   \n",
            "4          Fashion          1625                 2615      830008.48   \n",
            "5           Beauty          1579                 2542      814913.17   \n",
            "\n",
            "   avg_order_value  avg_discount_rate  unique_customers  revenue_share_pct  \n",
            "0           515.55               9.86              1370              18.14  \n",
            "1           518.54              10.15              1266              16.78  \n",
            "2           500.58               9.90              1298              16.54  \n",
            "3           498.83              10.29              1283              16.28  \n",
            "4           510.77              10.08              1237              16.27  \n",
            "5           516.09              10.00              1217              15.98  \n",
            "\n",
            "==================================================\n",
            "Query: City-wise Business Performance\n",
            "==================================================\n",
            "SQL: \n",
            "SELECT \n",
            "    customer_city,\n",
            "    COUNT(*) as total_orders,\n",
            "    ROUND(SUM(final_price), 2) as total_revenue,\n",
            "    ROUND(AVG(final_price), 2) as avg_order_value,\n",
            "    COUNT(DISTINCT customer_id) as unique_customers,\n",
            "    ROUND(AVG(delivery_days), 1) as avg_delivery_days,\n",
            "    ROUND(\n",
            "        SUM(final_price) / COUNT(DISTINCT customer_id), 2\n",
            "    ) as revenue_per_customer\n",
            "FROM orders\n",
            "GROUP BY customer_city\n",
            "ORDER BY total_revenue DESC;\n",
            "\n",
            "--------------------------------------------------\n",
            "  customer_city  total_orders  total_revenue  avg_order_value  \\\n",
            "0         Delhi          1279      664519.12           519.56   \n",
            "1          Pune          1301      657214.13           505.16   \n",
            "2        Mumbai          1253      645916.33           515.50   \n",
            "3     Bangalore          1271      642152.57           505.23   \n",
            "4     Hyderabad          1209      634611.82           524.91   \n",
            "5       Chennai          1272      626697.70           492.69   \n",
            "6     Ahmedabad          1205      618135.54           512.98   \n",
            "7       Kolkata          1210      611232.22           505.15   \n",
            "\n",
            "   unique_customers  avg_delivery_days  revenue_per_customer  \n",
            "0              1048                4.6                634.08  \n",
            "1              1055                4.5                622.95  \n",
            "2              1015                4.5                636.37  \n",
            "3              1051                4.4                610.99  \n",
            "4               992                4.5                639.73  \n",
            "5              1034                4.5                606.09  \n",
            "6               995                4.5                621.24  \n",
            "7              1003                4.5                609.40  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KPI Calculations with Statistical Analysis\n",
        "def calculate_kpis(df):\n",
        "    kpis = {}\n",
        "\n",
        "    # Basic KPIs\n",
        "    kpis['total_revenue'] = df['final_price'].sum()\n",
        "    kpis['total_orders'] = len(df)\n",
        "    kpis['avg_order_value'] = df['final_price'].mean()\n",
        "    kpis['unique_customers'] = df['customer_id'].nunique()\n",
        "    kpis['revenue_per_customer'] = kpis['total_revenue'] / kpis['unique_customers']\n",
        "\n",
        "    # Advanced Statistical KPIs\n",
        "    kpis['aov_std'] = df['final_price'].std()\n",
        "    kpis['aov_median'] = df['final_price'].median()\n",
        "    kpis['revenue_skewness'] = stats.skew(df['final_price'])\n",
        "    kpis['revenue_kurtosis'] = stats.kurtosis(df['final_price'])\n",
        "\n",
        "    # Business-specific KPIs\n",
        "    kpis['avg_discount_rate'] = df['discount_percent'].mean()\n",
        "    kpis['total_discount_given'] = df['discount_amount'].sum()\n",
        "    kpis['avg_delivery_days'] = df['delivery_days'].mean()\n",
        "\n",
        "    # Conversion and engagement metrics\n",
        "    repeat_customers = df.groupby('customer_id').size()\n",
        "    kpis['repeat_customer_rate'] = (repeat_customers > 1).sum() / len(repeat_customers)\n",
        "    kpis['avg_orders_per_customer'] = repeat_customers.mean()\n",
        "\n",
        "    return kpis\n",
        "\n",
        "kpis = calculate_kpis(df)\n",
        "\n",
        "print(\"Key Performance Indicators:\")\n",
        "print(\"=\"*40)\n",
        "for key, value in kpis.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU8r8CfgEL_M",
        "outputId": "8bb9037f-4bbd-4fa4-868d-898c7ebaec05"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Performance Indicators:\n",
            "========================================\n",
            "total_revenue: 5100479.43\n",
            "total_orders: 10000\n",
            "avg_order_value: 510.05\n",
            "unique_customers: 2896\n",
            "revenue_per_customer: 1761.22\n",
            "aov_std: 552.02\n",
            "aov_median: 331.14\n",
            "revenue_skewness: 3.02\n",
            "revenue_kurtosis: 14.19\n",
            "avg_discount_rate: 10.04\n",
            "total_discount_given: 565457.56\n",
            "avg_delivery_days: 4.49\n",
            "repeat_customer_rate: 0.89\n",
            "avg_orders_per_customer: 3.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Analysis for Business Insights\n",
        "def perform_statistical_analysis(df):\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STATISTICAL ANALYSIS FOR BUSINESS INSIGHTS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. Correlation Analysis\n",
        "    print(\"\\n1. CORRELATION ANALYSIS\")\n",
        "    print(\"-\" * 30)\n",
        "    numerical_cols = ['quantity', 'unit_price', 'total_price', 'final_price', 'discount_percent', 'delivery_days']\n",
        "    correlation_matrix = df[numerical_cols].corr()\n",
        "    print(correlation_matrix.round(3))\n",
        "\n",
        "    # 2. Weekend vs Weekday Analysis\n",
        "    print(\"\\n2. WEEKEND vs WEEKDAY PERFORMANCE\")\n",
        "    print(\"-\" * 40)\n",
        "    df['is_weekend'] = pd.to_datetime(df['order_date']).dt.weekday >= 5\n",
        "    weekend_stats = df.groupby('is_weekend').agg({\n",
        "        'final_price': ['count', 'mean', 'sum'],\n",
        "        'customer_id': 'nunique'\n",
        "    }).round(2)\n",
        "    print(weekend_stats)\n",
        "\n",
        "    # Statistical significance test\n",
        "    weekend_orders = df[df['is_weekend']]['final_price']\n",
        "    weekday_orders = df[~df['is_weekend']]['final_price']\n",
        "    t_stat, p_value = stats.ttest_ind(weekend_orders, weekday_orders)\n",
        "    print(f\"\\nT-test results (Weekend vs Weekday AOV):\")\n",
        "    print(f\"T-statistic: {t_stat:.3f}\")\n",
        "    print(f\"P-value: {p_value:.6f}\")\n",
        "    print(f\"Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
        "\n",
        "    # 3. Category Performance Analysis\n",
        "    print(\"\\n3. CATEGORY PERFORMANCE ANALYSIS\")\n",
        "    print(\"-\" * 40)\n",
        "    category_stats = df.groupby('product_category').agg({\n",
        "        'final_price': ['count', 'mean', 'sum', 'std'],\n",
        "        'discount_percent': 'mean'\n",
        "    }).round(2)\n",
        "    print(category_stats)\n",
        "\n",
        "    return correlation_matrix\n",
        "\n",
        "correlation_matrix = perform_statistical_analysis(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3F5AMhWERlh",
        "outputId": "6b85b664-30f0-4031-e399-f5ba42787d83"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "STATISTICAL ANALYSIS FOR BUSINESS INSIGHTS\n",
            "==================================================\n",
            "\n",
            "1. CORRELATION ANALYSIS\n",
            "------------------------------\n",
            "                  quantity  unit_price  total_price  final_price  \\\n",
            "quantity             1.000      -0.019        0.480        0.476   \n",
            "unit_price          -0.019       1.000        0.761        0.757   \n",
            "total_price          0.480       0.761        1.000        0.994   \n",
            "final_price          0.476       0.757        0.994        1.000   \n",
            "discount_percent    -0.007      -0.007       -0.008       -0.080   \n",
            "delivery_days        0.018       0.003        0.010        0.010   \n",
            "\n",
            "                  discount_percent  delivery_days  \n",
            "quantity                    -0.007          0.018  \n",
            "unit_price                  -0.007          0.003  \n",
            "total_price                 -0.008          0.010  \n",
            "final_price                 -0.080          0.010  \n",
            "discount_percent             1.000          0.009  \n",
            "delivery_days                0.009          1.000  \n",
            "\n",
            "2. WEEKEND vs WEEKDAY PERFORMANCE\n",
            "----------------------------------------\n",
            "           final_price                     customer_id\n",
            "                 count    mean         sum     nunique\n",
            "is_weekend                                            \n",
            "False             7154  494.42  3537108.18        2738\n",
            "True              2846  549.32  1563371.25        1822\n",
            "\n",
            "T-test results (Weekend vs Weekday AOV):\n",
            "T-statistic: 4.492\n",
            "P-value: 0.000007\n",
            "Significant difference: Yes\n",
            "\n",
            "3. CATEGORY PERFORMANCE ANALYSIS\n",
            "----------------------------------------\n",
            "                 final_price                            discount_percent\n",
            "                       count    mean        sum     std             mean\n",
            "product_category                                                        \n",
            "Bags                    1665  498.83  830554.79  540.64            10.29\n",
            "Beauty                  1579  516.09  814913.17  566.62            10.00\n",
            "Electronics             1795  515.55  925412.87  543.92             9.86\n",
            "Fashion                 1625  510.77  830008.48  558.72            10.08\n",
            "Home & Kitchen          1651  518.54  856110.48  579.27            10.15\n",
            "Kids                    1685  500.58  843479.64  523.78             9.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#excel dashboard\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, PatternFill, Alignment\n",
        "from openpyxl.chart import LineChart, BarChart, PieChart, Reference\n",
        "import openpyxl\n",
        "\n",
        "def create_excel_dashboard(df, kpis, monthly_data, product_performance):\n",
        "    # Create workbook with multiple sheets\n",
        "    wb = Workbook()\n",
        "\n",
        "    # Remove default sheet\n",
        "    wb.remove(wb.active)\n",
        "\n",
        "    # 1. KPI Summary Sheet\n",
        "    kpi_sheet = wb.create_sheet(\"KPI_Dashboard\")\n",
        "\n",
        "    # Headers\n",
        "    kpi_sheet['A1'] = \"Key Performance Indicators\"\n",
        "    kpi_sheet['A1'].font = Font(bold=True, size=16)\n",
        "    kpi_sheet['A1'].fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
        "\n",
        "    # KPI Data\n",
        "    row = 3\n",
        "    for key, value in kpis.items():\n",
        "        kpi_sheet[f'A{row}'] = key.replace('_', ' ').title()\n",
        "        if isinstance(value, float):\n",
        "            kpi_sheet[f'B{row}'] = round(value, 2)\n",
        "        else:\n",
        "            kpi_sheet[f'B{row}'] = value\n",
        "        row += 1\n",
        "\n",
        "    # 2. Monthly Trends Sheet\n",
        "    monthly_sheet = wb.create_sheet(\"Monthly_Trends\")\n",
        "\n",
        "    # Add monthly data\n",
        "    monthly_sheet['A1'] = \"Month\"\n",
        "    monthly_sheet['B1'] = \"Total Orders\"\n",
        "    monthly_sheet['C1'] = \"Total Revenue\"\n",
        "    monthly_sheet['D1'] = \"AOV\"\n",
        "    monthly_sheet['E1'] = \"Growth %\"\n",
        "\n",
        "    for idx, row_data in monthly_data.iterrows():\n",
        "        excel_row = idx + 2\n",
        "        monthly_sheet[f'A{excel_row}'] = row_data['month']\n",
        "        monthly_sheet[f'B{excel_row}'] = row_data['total_orders']\n",
        "        monthly_sheet[f'C{excel_row}'] = row_data['total_revenue']\n",
        "        monthly_sheet[f'D{excel_row}'] = row_data['avg_order_value']\n",
        "        monthly_sheet[f'E{excel_row}'] = row_data['revenue_growth_pct'] if not pd.isna(row_data['revenue_growth_pct']) else 0\n",
        "\n",
        "    # 3. Product Performance Sheet\n",
        "    product_sheet = wb.create_sheet(\"Product_Performance\")\n",
        "\n",
        "    # Add product data\n",
        "    for idx, col in enumerate(['Category', 'Orders', 'Revenue', 'AOV', 'Revenue Share %']):\n",
        "        product_sheet.cell(row=1, column=idx+1, value=col)\n",
        "\n",
        "    for idx, row_data in product_performance.iterrows():\n",
        "        excel_row = idx + 2\n",
        "        product_sheet[f'A{excel_row}'] = row_data['product_category']\n",
        "        product_sheet[f'B{excel_row}'] = row_data['total_orders']\n",
        "        product_sheet[f'C{excel_row}'] = row_data['total_revenue']\n",
        "        product_sheet[f'D{excel_row}'] = row_data['avg_order_value']\n",
        "        product_sheet[f'E{excel_row}'] = row_data['revenue_share_pct']\n",
        "\n",
        "    # Save Excel file\n",
        "    wb.save('Meesho_KPI_Dashboard.xlsx')\n",
        "    print(\"Excel dashboard created: Meesho_KPI_Dashboard.xlsx\")\n",
        "\n",
        "# Create Excel dashboard\n",
        "create_excel_dashboard(df, kpis, monthly_data, product_performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXvJ5ddiEXwq",
        "outputId": "20a64e52-9a08-4f8c-c8cc-4cefe9fc7a7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel dashboard created: Meesho_KPI_Dashboard.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create advanced Excel analysis with formulas\n",
        "def create_advanced_excel_analysis(df):\n",
        "    # Prepare data for Excel pivot analysis\n",
        "    excel_data = df.copy()\n",
        "    excel_data['order_month'] = pd.to_datetime(excel_data['order_date']).dt.to_period('M').astype(str)\n",
        "    excel_data['order_weekday'] = pd.to_datetime(excel_data['order_date']).dt.day_name()\n",
        "    excel_data['revenue_bucket'] = pd.cut(excel_data['final_price'],\n",
        "                                         bins=[0, 500, 1000, 2000, float('inf')],\n",
        "                                         labels=['Low', 'Medium', 'High', 'Premium'])\n",
        "\n",
        "    # Save to Excel for pivot table creation\n",
        "    with pd.ExcelWriter('Meesho_Advanced_Analysis.xlsx', engine='openpyxl') as writer:\n",
        "        excel_data.to_excel(writer, sheet_name='Raw_Data', index=False)\n",
        "\n",
        "        # Monthly summary\n",
        "        monthly_summary = excel_data.groupby('order_month').agg({\n",
        "            'final_price': ['sum', 'mean', 'count'],\n",
        "            'customer_id': 'nunique',\n",
        "            'discount_amount': 'sum'\n",
        "        }).round(2)\n",
        "        monthly_summary.to_excel(writer, sheet_name='Monthly_Summary')\n",
        "\n",
        "        # Category analysis\n",
        "        category_analysis = excel_data.groupby(['product_category', 'customer_city']).agg({\n",
        "            'final_price': ['sum', 'count'],\n",
        "            'customer_id': 'nunique'\n",
        "        }).round(2)\n",
        "        category_analysis.to_excel(writer, sheet_name='Category_City_Analysis')\n",
        "\n",
        "    print(\"Advanced Excel analysis created: Meesho_Advanced_Analysis.xlsx\")\n",
        "\n",
        "create_advanced_excel_analysis(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfjPwbwpEisK",
        "outputId": "b813fdb6-185b-485b-daa1-bd06c9531a08"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Advanced Excel analysis created: Meesho_Advanced_Analysis.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save this as dashboard.py\n",
        "dashboard_code = '''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Meesho Business Analytics Dashboard\",\n",
        "    page_icon=\"📊\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Load data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    conn = sqlite3.connect('meesho_analytics.db')\n",
        "    df = pd.read_sql_query(\"SELECT * FROM orders\", conn)\n",
        "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Sidebar filters\n",
        "st.sidebar.header(\"Filters\")\n",
        "date_range = st.sidebar.date_input(\n",
        "    \"Select Date Range\",\n",
        "    value=(df['order_date'].min(), df['order_date'].max()),\n",
        "    min_value=df['order_date'].min(),\n",
        "    max_value=df['order_date'].max()\n",
        ")\n",
        "\n",
        "categories = st.sidebar.multiselect(\n",
        "    \"Select Categories\",\n",
        "    options=df['product_category'].unique(),\n",
        "    default=df['product_category'].unique()\n",
        ")\n",
        "\n",
        "cities = st.sidebar.multiselect(\n",
        "    \"Select Cities\",\n",
        "    options=df['customer_city'].unique(),\n",
        "    default=df['customer_city'].unique()\n",
        ")\n",
        "\n",
        "# Filter data\n",
        "filtered_df = df[\n",
        "    (df['order_date'].dt.date >= date_range[0]) &\n",
        "    (df['order_date'].dt.date <= date_range[1]) &\n",
        "    (df['product_category'].isin(categories)) &\n",
        "    (df['customer_city'].isin(cities))\n",
        "]\n",
        "\n",
        "# Main dashboard\n",
        "st.title(\"📊 Meesho Business Analytics Dashboard\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# KPI Metrics Row\n",
        "col1, col2, col3, col4, col5 = st.columns(5)\n",
        "\n",
        "with col1:\n",
        "    total_revenue = filtered_df['final_price'].sum()\n",
        "    st.metric(\"Total Revenue\", f\"₹{total_revenue:,.0f}\")\n",
        "\n",
        "with col2:\n",
        "    total_orders = len(filtered_df)\n",
        "    st.metric(\"Total Orders\", f\"{total_orders:,}\")\n",
        "\n",
        "with col3:\n",
        "    aov = filtered_df['final_price'].mean()\n",
        "    st.metric(\"Average Order Value\", f\"₹{aov:.0f}\")\n",
        "\n",
        "with col4:\n",
        "    unique_customers = filtered_df['customer_id'].nunique()\n",
        "    st.metric(\"Unique Customers\", f\"{unique_customers:,}\")\n",
        "\n",
        "with col5:\n",
        "    repeat_rate = (filtered_df.groupby('customer_id').size() > 1).mean() * 100\n",
        "    st.metric(\"Repeat Customer Rate\", f\"{repeat_rate:.1f}%\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Charts Row 1\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    # Monthly Revenue Trend\n",
        "    monthly_revenue = filtered_df.groupby(filtered_df['order_date'].dt.to_period('M')).agg({\n",
        "        'final_price': 'sum',\n",
        "        'order_id': 'count'\n",
        "    }).reset_index()\n",
        "    monthly_revenue['order_date'] = monthly_revenue['order_date'].astype(str)\n",
        "\n",
        "    fig_monthly = px.line(monthly_revenue, x='order_date', y='final_price',\n",
        "                         title='Monthly Revenue Trend',\n",
        "                         labels={'final_price': 'Revenue (₹)', 'order_date': 'Month'})\n",
        "    fig_monthly.update_layout(showlegend=False)\n",
        "    st.plotly_chart(fig_monthly, use_container_width=True)\n",
        "\n",
        "with col2:\n",
        "    # Category Performance\n",
        "    category_revenue = filtered_df.groupby('product_category')['final_price'].sum().sort_values(ascending=True)\n",
        "\n",
        "    fig_category = px.bar(x=category_revenue.values, y=category_revenue.index,\n",
        "                         orientation='h',\n",
        "                         title='Revenue by Category',\n",
        "                         labels={'x': 'Revenue (₹)', 'y': 'Category'})\n",
        "    fig_category.update_layout(showlegend=False)\n",
        "    st.plotly_chart(fig_category, use_container_width=True)\n",
        "\n",
        "# Charts Row 2\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    # City Performance\n",
        "    city_performance = filtered_df.groupby('customer_city').agg({\n",
        "        'final_price': 'sum',\n",
        "        'customer_id': 'nunique'\n",
        "    }).sort_values('final_price', ascending=False).head(8)\n",
        "\n",
        "    fig_city = px.scatter(city_performance, x='customer_id', y='final_price',\n",
        "                         hover_data=['final_price'],\n",
        "                         title='City Performance: Revenue vs Customers',\n",
        "                         labels={'customer_id': 'Unique Customers', 'final_price': 'Revenue (₹)'})\n",
        "\n",
        "    for i, city in enumerate(city_performance.index):\n",
        "        fig_city.add_annotation(\n",
        "            x=city_performance.loc[city, 'customer_id'],\n",
        "            y=city_performance.loc[city, 'final_price'],\n",
        "            text=city,\n",
        "            showarrow=True,\n",
        "            arrowhead=2\n",
        "        )\n",
        "\n",
        "    st.plotly_chart(fig_city, use_container_width=True)\n",
        "\n",
        "with col2:\n",
        "    # Payment Method Distribution\n",
        "    payment_dist = filtered_df['payment_method'].value_counts()\n",
        "\n",
        "    fig_payment = px.pie(values=payment_dist.values, names=payment_dist.index,\n",
        "                        title='Payment Method Distribution')\n",
        "    st.plotly_chart(fig_payment, use_container_width=True)\n",
        "\n",
        "# Detailed Analysis Section\n",
        "st.markdown(\"---\")\n",
        "st.header(\"📈 Detailed Analysis\")\n",
        "\n",
        "tab1, tab2, tab3 = st.tabs([\"Customer Segmentation\", \"Product Analysis\", \"Time Analysis\"])\n",
        "\n",
        "with tab1:\n",
        "    # Customer Segmentation\n",
        "    customer_metrics = filtered_df.groupby('customer_id').agg({\n",
        "        'final_price': ['sum', 'count', 'mean'],\n",
        "        'order_date': 'max'\n",
        "    }).round(2)\n",
        "\n",
        "    customer_metrics.columns = ['total_spent', 'order_count', 'avg_order_value', 'last_order']\n",
        "    customer_metrics['days_since_last_order'] = (datetime.now() - pd.to_datetime(customer_metrics['last_order'])).dt.days\n",
        "\n",
        "    # Segmentation logic\n",
        "    def segment_customers(row):\n",
        "        if row['total_spent'] >= 5000 and row['order_count'] >= 5:\n",
        "            return 'High Value'\n",
        "        elif row['total_spent'] >= 2000 and row['order_count'] >= 3:\n",
        "            return 'Medium Value'\n",
        "        elif row['days_since_last_order'] <= 30:\n",
        "            return 'Recent Active'\n",
        "        elif row['days_since_last_order'] > 90:\n",
        "            return 'At Risk'\n",
        "        else:\n",
        "            return 'Regular'\n",
        "\n",
        "    customer_metrics['segment'] = customer_metrics.apply(segment_customers, axis=1)\n",
        "    segment_summary = customer_metrics.groupby('segment').agg({\n",
        "        'total_spent': ['count', 'mean'],\n",
        "        'order_count': 'mean',\n",
        "        'avg_order_value': 'mean'\n",
        "    }).round(2)\n",
        "\n",
        "    st.subheader(\"Customer Segmentation Analysis\")\n",
        "    st.dataframe(segment_summary)\n",
        "\n",
        "    # Segment distribution pie chart\n",
        "    segment_dist = customer_metrics['segment'].value_counts()\n",
        "    fig_segments = px.pie(values=segment_dist.values, names=segment_dist.index,\n",
        "                         title='Customer Segment Distribution')\n",
        "    st.plotly_chart(fig_segments, use_container_width=True)\n",
        "\n",
        "with tab2:\n",
        "    # Product Analysis\n",
        "    st.subheader(\"Product Category Performance\")\n",
        "\n",
        "    product_analysis = filtered_df.groupby('product_category').agg({\n",
        "        'final_price': ['sum', 'count', 'mean'],\n",
        "        'discount_percent': 'mean',\n",
        "        'customer_id': 'nunique'\n",
        "    }).round(2)\n",
        "\n",
        "    product_analysis.columns = ['total_revenue', 'total_orders', 'avg_order_value', 'avg_discount', 'unique_customers']\n",
        "    product_analysis['revenue_per_customer'] = (product_analysis['total_revenue'] / product_analysis['unique_customers']).round(2)\n",
        "\n",
        "    st.dataframe(product_analysis.sort_values('total_revenue', ascending=False))\n",
        "\n",
        "    # Discount vs Revenue analysis\n",
        "    fig_discount = px.scatter(product_analysis, x='avg_discount', y='total_revenue',\n",
        "                             size='total_orders', hover_name=product_analysis.index,\n",
        "                             title='Discount Rate vs Revenue by Category')\n",
        "    st.plotly_chart(fig_discount, use_container_width=True)\n",
        "\n",
        "with tab3:\n",
        "    # Time Analysis\n",
        "    st.subheader(\"Time-based Analysis\")\n",
        "\n",
        "    # Weekday performance\n",
        "    filtered_df['weekday'] = filtered_df['order_date'].dt.day_name()\n",
        "    weekday_performance = filtered_df.groupby('weekday').agg({\n",
        "        'final_price': ['sum', 'count', 'mean']\n",
        "    }).round(2)\n",
        "    weekday_performance.columns = ['total_revenue', 'total_orders', 'avg_order_value']\n",
        "\n",
        "    # Reorder by weekday\n",
        "    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    weekday_performance = weekday_performance.reindex(weekday_order)\n",
        "\n",
        "    fig_weekday = px.bar(weekday_performance, x=weekday_performance.index, y='total_revenue',\n",
        "                        title='Revenue by Day of Week')\n",
        "    st.plotly_chart(fig_weekday, use_container_width=True)\n",
        "\n",
        "    # Hour analysis (if hour data available)\n",
        "    if 'order_hour' in filtered_df.columns:\n",
        "        hourly_orders = filtered_df.groupby('order_hour')['final_price'].sum()\n",
        "        fig_hourly = px.line(x=hourly_orders.index, y=hourly_orders.values,\n",
        "                           title='Revenue by Hour of Day')\n",
        "        st.plotly_chart(fig_hourly, use_container_width=True)\n",
        "\n",
        "# Insights and Recommendations\n",
        "st.markdown(\"---\")\n",
        "st.header(\"💡 Key Insights & Recommendations\")\n",
        "\n",
        "insights = [\n",
        "    f\"📊 **Revenue Performance**: Total revenue of ₹{total_revenue:,.0f} from {total_orders:,} orders\",\n",
        "    f\"💰 **Customer Value**: Average order value is ₹{aov:.0f} with {repeat_rate:.1f}% repeat customers\",\n",
        "    f\"🏆 **Top Category**: {category_revenue.index[-1]} generates highest revenue\",\n",
        "    f\"🎯 **Growth Opportunity**: Focus on customer retention to improve repeat rate\",\n",
        "    f\"📈 **Recommendation**: Implement targeted campaigns for 'At Risk' customer segment\"\n",
        "]\n",
        "\n",
        "for insight in insights:\n",
        "    st.markdown(insight)\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"*Dashboard created for Meesho Business Analyst Role - Data-driven insights for business growth*\")\n",
        "'''\n",
        "\n",
        "# Save dashboard code to file\n",
        "with open('dashboard.py', 'w') as f:\n",
        "    f.write(dashboard_code)\n",
        "\n",
        "print(\"Streamlit dashboard created! Run with: streamlit run dashboard.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltx5QdOHEral",
        "outputId": "d29a4f82-301d-404b-8345-229c67a534a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit dashboard created! Run with: streamlit run dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install schedule\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6-lSBqkF0Pz",
        "outputId": "4e00649c-7964-4fac-de20-fcdb04156fce"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#date refresh automation\n",
        "import schedule\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def automated_data_refresh():\n",
        "    \"\"\"Automated function to refresh data and regenerate reports\"\"\"\n",
        "    print(f\"Starting automated refresh at {datetime.now()}\")\n",
        "\n",
        "    # 1. Refresh data (in real scenario, this would connect to production DB)\n",
        "    df_new = generate_ecommerce_data(1000)  # New daily data\n",
        "\n",
        "    # 2. Append to existing database\n",
        "    conn = sqlite3.connect('meesho_analytics.db')\n",
        "    df_new.to_sql('orders', conn, if_exists='append', index=False)\n",
        "    conn.close()\n",
        "\n",
        "    # 3. Recalculate KPIs\n",
        "    df_updated = pd.read_sql_query(\"SELECT * FROM orders\", sqlite3.connect('meesho_analytics.db'))\n",
        "    updated_kpis = calculate_kpis(df_updated)\n",
        "\n",
        "    # 4. Generate updated Excel report\n",
        "    # create_excel_dashboard(df_updated, updated_kpis, monthly_data, product_performance)\n",
        "\n",
        "    # 5. Send email notification (placeholder)\n",
        "    print(\"Data refresh completed successfully!\")\n",
        "    print(f\"Updated KPIs: Total Revenue = ₹{updated_kpis['total_revenue']:,.2f}\")\n",
        "\n",
        "# Schedule automation (uncomment to run)\n",
        "# schedule.every().day.at(\"06:00\").do(automated_data_refresh)\n",
        "# schedule.every().monday.at(\"09:00\").do(automated_data_refresh)\n",
        "\n",
        "print(\"Automation script ready. Uncomment scheduling lines to activate.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrQL2eBUEwQa",
        "outputId": "b29d40e1-8e43-4afa-c1b1-5107b8198e5a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automation script ready. Uncomment scheduling lines to activate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def kpi_monitoring_system(df, threshold_dict):\n",
        "    \"\"\"Monitor KPIs and generate alerts if thresholds are breached\"\"\"\n",
        "\n",
        "    current_kpis = calculate_kpis(df)\n",
        "    alerts = []\n",
        "\n",
        "    # Check thresholds\n",
        "    for kpi, threshold in threshold_dict.items():\n",
        "        if kpi in current_kpis:\n",
        "            current_value = current_kpis[kpi]\n",
        "\n",
        "            if isinstance(threshold, dict):\n",
        "                if 'min' in threshold and current_value < threshold['min']:\n",
        "                    alerts.append(f\"🚨 ALERT: {kpi} is below minimum threshold: {current_value:.2f} < {threshold['min']}\")\n",
        "                if 'max' in threshold and current_value > threshold['max']:\n",
        "                    alerts.append(f\"⚠️  WARNING: {kpi} is above maximum threshold: {current_value:.2f} > {threshold['max']}\")\n",
        "\n",
        "    return alerts\n",
        "\n",
        "# Example thresholds\n",
        "thresholds = {\n",
        "    'avg_order_value': {'min': 200, 'max': 2000},\n",
        "    'repeat_customer_rate': {'min': 0.3},\n",
        "    'avg_discount_rate': {'max': 15}\n",
        "}\n",
        "\n",
        "alerts = kpi_monitoring_system(df, thresholds)\n",
        "if alerts:\n",
        "    print(\"KPI ALERTS:\")\n",
        "    for alert in alerts:\n",
        "        print(alert)\n",
        "else:\n",
        "    print(\"✅ All KPIs within normal ranges\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hj5Fp8LE0hS",
        "outputId": "cc02f132-228f-4dec-ae2a-80c222820d73"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All KPIs within normal ranges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating Business Insights and actionable Recommendations\n",
        "def generate_business_intelligence_report(df):\n",
        "    \"\"\"Generate comprehensive business intelligence with actionable insights\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BUSINESS INTELLIGENCE REPORT - MEESHO ANALYTICS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Executive Summary\n",
        "    print(\"\\n📊 EXECUTIVE SUMMARY\")\n",
        "    print(\"-\" * 30)\n",
        "    total_revenue = df['final_price'].sum()\n",
        "    total_orders = len(df)\n",
        "    unique_customers = df['customer_id'].nunique()\n",
        "\n",
        "    print(f\"• Total Revenue: ₹{total_revenue:,.2f}\")\n",
        "    print(f\"• Total Orders: {total_orders:,}\")\n",
        "    print(f\"• Unique Customers: {unique_customers:,}\")\n",
        "    print(f\"• Average Order Value: ₹{df['final_price'].mean():.2f}\")\n",
        "    print(f\"• Revenue per Customer: ₹{total_revenue/unique_customers:.2f}\")\n",
        "\n",
        "    # 2. Key Performance Drivers\n",
        "    print(\"\\n🎯 KEY PERFORMANCE DRIVERS\")\n",
        "    print(\"-\" * 35)\n",
        "\n",
        "    # Top performing categories\n",
        "    top_categories = df.groupby('product_category')['final_price'].sum().sort_values(ascending=False)\n",
        "    print(f\"• Top Revenue Category: {top_categories.index[0]} (₹{top_categories.iloc[0]:,.0f})\")\n",
        "\n",
        "    # City performance\n",
        "    top_cities = df.groupby('customer_city')['final_price'].sum().sort_values(ascending=False)\n",
        "    print(f\"• Top Revenue City: {top_cities.index[0]} (₹{top_cities.iloc[0]:,.0f})\")\n",
        "\n",
        "    # Customer behavior insights\n",
        "    repeat_customers = df.groupby('customer_id').size()\n",
        "    repeat_rate = (repeat_customers > 1).sum() / len(repeat_customers) * 100\n",
        "    print(f\"• Repeat Customer Rate: {repeat_rate:.1f}%\")\n",
        "\n",
        "    # 3. Growth Opportunities\n",
        "    print(\"\\n📈 GROWTH OPPORTUNITIES\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Low performing segments\n",
        "    low_performing_cities = top_cities.tail(3)\n",
        "    print(\"• Cities with growth potential:\")\n",
        "    for city, revenue in low_performing_cities.items():\n",
        "        print(f\"  - {city}: ₹{revenue:,.0f}\")\n",
        "\n",
        "    # Discount analysis\n",
        "    avg_discount = df['discount_percent'].mean()\n",
        "    high_discount_orders = df[df['discount_percent'] > avg_discount]\n",
        "    discount_impact = high_discount_orders['final_price'].mean() - df[df['discount_percent'] <= avg_discount]['final_price'].mean()\n",
        "\n",
        "    print(f\"• Average Discount Rate: {avg_discount:.1f}%\")\n",
        "    print(f\"• Discount Impact on AOV: ₹{discount_impact:.0f}\")\n",
        "\n",
        "    # 4. Actionable Recommendations\n",
        "    print(\"\\n💡 ACTIONABLE RECOMMENDATIONS\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    recommendations = [\n",
        "        \"1. CUSTOMER RETENTION: Implement loyalty program to increase repeat rate from {:.1f}% to 40%+\".format(repeat_rate),\n",
        "        \"2. CATEGORY EXPANSION: Focus marketing on underperforming categories with high-margin potential\",\n",
        "        \"3. GEOGRAPHIC EXPANSION: Increase marketing spend in low-revenue cities with high growth potential\",\n",
        "        \"4. PRICING OPTIMIZATION: Review discount strategy - current average of {:.1f}% may be impacting margins\".format(avg_discount),\n",
        "        \"5. PERSONALIZATION: Implement customer segmentation for targeted campaigns\",\n",
        "        \"6. INVENTORY MANAGEMENT: Focus on fast-moving categories: {}\".format(', '.join(top_categories.head(3).index))\n",
        "    ]\n",
        "\n",
        "    for rec in recommendations:\n",
        "        print(f\"• {rec}\")\n",
        "\n",
        "    # 5. Predicted Impact\n",
        "    print(\"\\n📊 PREDICTED BUSINESS IMPACT\")\n",
        "    print(\"-\" * 35)\n",
        "\n",
        "    # Calculate potential improvements\n",
        "    potential_repeat_improvement = (0.4 - repeat_rate/100) * unique_customers * df['final_price'].mean()\n",
        "    potential_city_expansion = low_performing_cities.sum() * 0.5  # 50% growth in low cities\n",
        "\n",
        "    print(f\"• Potential Revenue from Improved Retention: ₹{potential_repeat_improvement:,.0f}\")\n",
        "    print(f\"• Potential Revenue from City Expansion: ₹{potential_city_expansion:,.0f}\")\n",
        "    print(f\"• Total Potential Revenue Increase: ₹{potential_repeat_improvement + potential_city_expansion:,.0f}\")\n",
        "\n",
        "    return {\n",
        "        'recommendations': recommendations,\n",
        "        'potential_revenue_increase': potential_repeat_improvement + potential_city_expansion,\n",
        "        'key_metrics': {\n",
        "            'total_revenue': total_revenue,\n",
        "            'repeat_rate': repeat_rate,\n",
        "            'avg_discount': avg_discount,\n",
        "            'top_category': top_categories.index[0],\n",
        "            'top_city': top_cities.index[0]\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Generate the comprehensive report\n",
        "business_report = generate_business_intelligence_report(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QygGArkoGJbl",
        "outputId": "58c51824-0156-467f-97c4-762750271aac"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BUSINESS INTELLIGENCE REPORT - MEESHO ANALYTICS\n",
            "============================================================\n",
            "\n",
            "📊 EXECUTIVE SUMMARY\n",
            "------------------------------\n",
            "• Total Revenue: ₹5,100,479.43\n",
            "• Total Orders: 10,000\n",
            "• Unique Customers: 2,896\n",
            "• Average Order Value: ₹510.05\n",
            "• Revenue per Customer: ₹1761.22\n",
            "\n",
            "🎯 KEY PERFORMANCE DRIVERS\n",
            "-----------------------------------\n",
            "• Top Revenue Category: Electronics (₹925,413)\n",
            "• Top Revenue City: Delhi (₹664,519)\n",
            "• Repeat Customer Rate: 88.5%\n",
            "\n",
            "📈 GROWTH OPPORTUNITIES\n",
            "------------------------------\n",
            "• Cities with growth potential:\n",
            "  - Chennai: ₹626,698\n",
            "  - Ahmedabad: ₹618,136\n",
            "  - Kolkata: ₹611,232\n",
            "• Average Discount Rate: 10.0%\n",
            "• Discount Impact on AOV: ₹-73\n",
            "\n",
            "💡 ACTIONABLE RECOMMENDATIONS\n",
            "----------------------------------------\n",
            "• 1. CUSTOMER RETENTION: Implement loyalty program to increase repeat rate from 88.5% to 40%+\n",
            "• 2. CATEGORY EXPANSION: Focus marketing on underperforming categories with high-margin potential\n",
            "• 3. GEOGRAPHIC EXPANSION: Increase marketing spend in low-revenue cities with high growth potential\n",
            "• 4. PRICING OPTIMIZATION: Review discount strategy - current average of 10.0% may be impacting margins\n",
            "• 5. PERSONALIZATION: Implement customer segmentation for targeted campaigns\n",
            "• 6. INVENTORY MANAGEMENT: Focus on fast-moving categories: Electronics, Home & Kitchen, Kids\n",
            "\n",
            "📊 PREDICTED BUSINESS IMPACT\n",
            "-----------------------------------\n",
            "• Potential Revenue from Improved Retention: ₹-716,413\n",
            "• Potential Revenue from City Expansion: ₹928,033\n",
            "• Total Potential Revenue Increase: ₹211,619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def create_project_structure():\n",
        "    \"\"\"Create organized project structure\"\"\"\n",
        "\n",
        "    project_structure = {\n",
        "        'data/': ['meesho_analytics.db'],\n",
        "        'reports/': ['Meesho_KPI_Dashboard.xlsx', 'Meesho_Advanced_Analysis.xlsx'],\n",
        "        'scripts/': ['data_generation.py', 'analytics.py', 'automation.py'],\n",
        "        'dashboard/': ['dashboard.py'],\n",
        "        'documentation/': ['README.md', 'business_requirements.md']\n",
        "    }\n",
        "\n",
        "    print(\"PROJECT STRUCTURE:\")\n",
        "    print(\"=\"*40)\n",
        "    for folder, files in project_structure.items():\n",
        "        print(f\"📁 {folder}\")\n",
        "        for file in files:\n",
        "            print(f\"   📄 {file}\")\n",
        "\n",
        "    return project_structure\n",
        "\n",
        "project_files = create_project_structure()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sdvVTbpGZj_",
        "outputId": "02f8c331-7f39-43c6-e059-16986f3acefb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT STRUCTURE:\n",
            "========================================\n",
            "📁 data/\n",
            "   📄 meesho_analytics.db\n",
            "📁 reports/\n",
            "   📄 Meesho_KPI_Dashboard.xlsx\n",
            "   📄 Meesho_Advanced_Analysis.xlsx\n",
            "📁 scripts/\n",
            "   📄 data_generation.py\n",
            "   📄 analytics.py\n",
            "   📄 automation.py\n",
            "📁 dashboard/\n",
            "   📄 dashboard.py\n",
            "📁 documentation/\n",
            "   📄 README.md\n",
            "   📄 business_requirements.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create README documentation\n",
        "readme_content = \"\"\"\n",
        "# Meesho KPI Optimization & Dashboard Automation Project\n",
        "\n",
        "## Project Overview\n",
        "This project demonstrates comprehensive business analytics capabilities for the Meesho Business Analyst role, showcasing advanced SQL, Excel, Python, and statistical analysis skills.\n",
        "\n",
        "## Key Features\n",
        "- ✅ Advanced SQL queries for business analytics\n",
        "- ✅ Statistical analysis and correlation studies\n",
        "- ✅ Interactive Streamlit dashboard\n",
        "- ✅ Automated Excel reporting with multiple sheets\n",
        "- ✅ KPI monitoring and alerting system\n",
        "- ✅ Business intelligence with actionable insights\n",
        "- ✅ Data automation and scheduling\n",
        "\n",
        "## Technical Skills Demonstrated\n",
        "1. **Advanced SQL**: Complex joins, window functions, CTEs, statistical queries\n",
        "2. **Excel Integration**: Multi-sheet dashboards, pivot analysis, automated reporting\n",
        "3. **Python Analytics**: Pandas, NumPy, statistical analysis, data visualization\n",
        "4. **Business Intelligence**: KPI calculation, trend analysis, customer segmentation\n",
        "5. **Dashboard Creation**: Interactive Streamlit application\n",
        "6. **Automation**: Scheduled data refresh, alert systems\n",
        "\n",
        "## Business Impact\n",
        "- Identified key performance drivers across categories and cities\n",
        "- Developed customer segmentation for targeted marketing\n",
        "- Created automated monitoring for critical KPIs\n",
        "- Generated actionable recommendations with projected revenue impact\n",
        "- Built scalable analytics infrastructure for ongoing business insights\n",
        "\n",
        "## Files Description\n",
        "- `dashboard.py`: Interactive Streamlit dashboard\n",
        "- `meesho_analytics.db`: SQLite database with business data\n",
        "- `Meesho_KPI_Dashboard.xlsx`: Executive KPI dashboard\n",
        "- `Meesho_Advanced_Analysis.xlsx`: Detailed analytical reports\n",
        "\n",
        "## Running the Project\n",
        "1. Install requirements: `pip install -r requirements.txt`\n",
        "2. Run data generation: `python data_generation.py`\n",
        "3. Launch dashboard: `streamlit run dashboard.py`\n",
        "4. View Excel reports in the reports/ folder\n",
        "\n",
        "## Key Insights Generated\n",
        "- Revenue growth opportunities in underperforming cities\n",
        "- Customer retention strategies to improve repeat rate\n",
        "- Category performance optimization recommendations\n",
        "- Discount strategy impact analysis\n",
        "\n",
        "This project demonstrates the complete data → insight → action journey essential for business analyst roles.\n",
        "\"\"\"\n",
        "\n",
        "# Save README\n",
        "with open('README.md', 'w') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"✅ Complete KPI Optimization & Dashboard Automation Project Created!\")\n",
        "print(\"\\nProject includes:\")\n",
        "print(\"- Synthetic e-commerce dataset (10,000+ orders)\")\n",
        "print(\"- Advanced SQL analytics queries\")\n",
        "print(\"- Statistical analysis and correlation studies\")\n",
        "print(\"- Interactive Streamlit dashboard\")\n",
        "print(\"- Automated Excel reporting\")\n",
        "print(\"- Business intelligence with actionable insights\")\n",
        "print(\"- Complete documentation and project structure\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Xll3kvGeIn",
        "outputId": "946dd860-7ebd-4209-91e2-4f29d1b86e76"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Complete KPI Optimization & Dashboard Automation Project Created!\n",
            "\n",
            "Project includes:\n",
            "- Synthetic e-commerce dataset (10,000+ orders)\n",
            "- Advanced SQL analytics queries\n",
            "- Statistical analysis and correlation studies\n",
            "- Interactive Streamlit dashboard\n",
            "- Automated Excel reporting\n",
            "- Business intelligence with actionable insights\n",
            "- Complete documentation and project structure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run KPI_optimization.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYkF9723RBS-",
        "outputId": "cd012795-a2c5-4feb-9fbf-9e642059edfe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Streamlit requires raw Python (.py) files, not .ipynb.\n",
            "For more information, please see https://docs.streamlit.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "18B9bGxERU0u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}